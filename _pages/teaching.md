---
layout: page
permalink: /teaching/
title: teaching
description: Welcome to my teaching materials collection. ⚠️ These page and course are currently under development.
nav: true
nav_order: 6
---

<div class="course-container" markdown="1">
  <div class="course-card">
    <div class="course-header">
      <div class="header-left">
        <h3>Transformer Architectures</h3>
      </div>
    </div>
    <div class="course-content">
      <p class="course-description">End-to-end implementation of transformer architectures with production-grade practices.</p>

      <!-- Part 1: Core Implementation -->
      <div class="course-section">
        <div class="section-header">
          <div class="header-left">
            <h3>Part 1: Core Implementation</h3>
          </div>
          <a href="https://github.com/xmarva/transformer-architectures" class="github-link"><i class="fab fa-github"></i> GitHub</a>
        </div>
        <div class="section-content">
          <table class="table">
            <thead>
              <tr>
                <th>Notebook</th>
                <th>English</th>
                <th>Russian</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="https://xmarva.github.io/blog/2025/tokenization/">1. Understanding Tokenization: Byte-Pair Encoding</a></td>
                <td>
                  <a href="https://www.kaggle.com/code/qmarva/1-bpe-tokenization-algorithm-eng?scriptVersionId=231677033" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="https://colab.research.google.com/drive/1lmfuMdC8v-lXL_MuyC0uBewdLLCTQzCO?usp=sharing" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
                <td>
                  <a href="https://www.kaggle.com/code/qmarva/bpe-tokenization" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="https://colab.research.google.com/drive/1nzhgsD2-eyrnPr28wtKZTtf7YMJGiQbe?usp=sharing" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
              </tr>
              <tr>
                <td>2. Implementing Transformer Architecture </td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
                <td>
                  <a href="https://www.kaggle.com/code/qmarva/building-transformer" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
              </tr>
              <tr>
                <td>3. Improving Architecture with SoTA Techniques </td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
              </tr>
              <tr>
                <td>4. Evaluation Metrics: BLEU, ROUGE, METEOR, WandB</td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
              </tr>
              <tr>
                <td>5. Complete Transformer: End-to-End Pipeline</td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
              </tr>
              <tr>
                <td>6. Model Deployment and Monitoring</td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
                <td>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                  <a href="#" class="badge-link">
                    <img src="https://img.shields.io/badge/Colab-F9AB00?style=plastic&logo=google-colab&logoColor=white" alt="Colab">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>

      <!-- Part 2: Transformer-Based Architectures -->
      <div class="course-section">
        <div class="section-header">
          <div class="header-left">
            <h3>Part 2: Transformer-Based Architectures</h3>
          </div>
          <a href="#" class="github-link"><i class="fab fa-github"></i> GitHub</a>
        </div>
        <div class="section-content">
          <table class="table">
            <thead>
              <tr>
                <th>Notebook</th>
                <th>English</th>
                <th>Russian</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>1. BERT: Bidirectional Encoder Representations</td>
                <td>
                  <a href="https://github.com/xmarva/transformer-based-architectures/blob/main/notebooks/01-bert-explained-and-fine-tuned-for-ner.ipynb" class="badge-link">
                    <img src="https://img.shields.io/badge/GitHub-0F0F0F?style=plastic&logo=github&logoColor=white" alt="GitHub">
                  </a>
                  <a href="https://www.kaggle.com/code/qmarva/bert-explained-and-fine-tuned-for-ner?scriptVersionId=235335954" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                </td>
                <td></td>
              </tr>
              <tr>
                <td>2. GPT: Generative Pre-trained Transformers</td>
                <td>
                  <a href="https://github.com/xmarva/transformer-based-architectures/blob/main/notebooks/02-gpt-explained-and-fine-tuned-for-reasoning.ipynb" class="badge-link">
                    <img src="https://img.shields.io/badge/GitHub-0F0F0F?style=plastic&logo=github&logoColor=white" alt="GitHub">
                  </a>
                  <a href="https://www.kaggle.com/code/qmarva/gpt-explained-and-fine-tuned-for-reasoning?scriptVersionId=235487807" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                </td>
                <td></td>
              </tr>
              <tr>
                <td>3. T5: Text-to-Text Transfer Framework</td>
                <td>
                  <a href="https://github.com/xmarva/transformer-based-architectures/blob/main/notebooks/03-t5-explained-and-fine-tuned-for-summarization.ipynb" class="badge-link">
                    <img src="https://img.shields.io/badge/GitHub-0F0F0F?style=plastic&logo=github&logoColor=white" alt="GitHub">
                  </a>
                  <a href="https://www.kaggle.com/code/qmarva/t5-explained-and-fine-tuned-for-summarization" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                </td>
                <td></td>
              </tr>
              <tr>
                <td>4. Mixture of Experts: Switch Transformers</td>
                <td>
                  <a href="hhttps://github.com/xmarva/transformer-based-architectures/blob/main/notebooks/04-moe-explained-and-fine-tuned.ipynb" class="badge-link">
                    <img src="https://img.shields.io/badge/GitHub-0F0F0F?style=plastic&logo=github&logoColor=white" alt="GitHub">
                  </a>
                  <a href="https://www.kaggle.com/code/qmarva/moe-explained-and-fine-tuned" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                </td>
                <td></td>
              </tr>
              <tr>
                <td>5. Vision Transformers: ViT, DeiT</td>
                <td>
                  <a href="https://github.com/xmarva/transformer-based-architectures/blob/main/notebooks/05-vision-transformer-explained-and-fine-tuned.ipynb" class="badge-link">
                    <img src="https://img.shields.io/badge/GitHub-0F0F0F?style=plastic&logo=github&logoColor=white" alt="GitHub">
                  </a>
                  <a href="https://www.kaggle.com/code/qmarva/vision-transformer-explained-and-fine-tuned" class="badge-link">
                    <img src="https://img.shields.io/badge/Kaggle-20BEFF?style=plastic&logo=kaggle&logoColor=white" alt="Kaggle">
                  </a>
                </td>
                <td></td>
              </tr>
              <tr>
                <td>6. Longformers: Efficient Long-Context Attention</td>
                <td>
                  <a href="https://github.com/xmarva/transformer-based-architectures/blob/main/05-Longformer.ipynb" class="badge-link">
                    <img src="https://img.shields.io/badge/GitHub-0F0F0F?style=plastic&logo=github&logoColor=white" alt="GitHub">
                  </a>
                </td>
                <td></td>
              </tr>
              <tr>
                <td>7. Multimodal Architectures: CLIP, Flamingo</td>
                <td>
                  <a href="https://github.com/xmarva/transformer-based-architectures/blob/main/07-CLIP.ipynb" class="badge-link">
                    <img src="https://img.shields.io/badge/GitHub-0F0F0F?style=plastic&logo=github&logoColor=white" alt="GitHub">
                  </a>
                </td>
                <td></td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>

      <!-- Part 3: Optimization and SoTA Techniques -->
      <div class="course-section">
        <div class="section-header">
          <div class="header-left">
            <h3>Part 3: Optimization and SoTA Techniques</h3>
          </div>
          <a href="#" class="github-link"><i class="fab fa-github"></i> GitHub</a>
        </div>
        <div class="section-content">
          <table class="table">
            <thead>
              <tr>
                <th>Notebook</th>
                <th>English</th>
                <th>Russian</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>1. Quantization: 8-bit, QLoRA, Quantization-Aware Training</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>2. Pruning: Structured vs. Unstructured Methods</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>3. PEFT: LoRA, Adapters, Prompt Tuning</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>4. Knowledge Distillation: TinyBERT, DistilGPT-2</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>5. Mixed-Precision Training: FP16, NVIDIA AMP</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>6. Distributed Training: DeepSpeed, ZeRO, Tensor Parallelism</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>7. Efficient Attention: Flash Attention, Sparse Patterns</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>8. Dynamic Computation: Early Exit, Adaptive Strategies</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>9. Hardware Optimizations: ONNX, TensorRT, TPU/XLA</td>
                <td></td>
                <td></td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</div>

<style>
.course-container {
  margin-bottom: 3rem;
}

.course-card {
  background-color: var(--global-bg-color);
  border-radius: 8px;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
  padding: 2rem;
  margin-bottom: 2rem;
  transition: box-shadow 0.3s ease;
  color: var(--global-text-color);
}

.course-card:hover {
  box-shadow: 0 6px 16px rgba(0, 0, 0, 0.12);
}

.course-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
  border-bottom: 1px solid var(--global-divider-color);
  padding-bottom: 0.75rem;
}

.header-left {
  display: flex;
  align-items: center;
}

.course-header h3 {
  margin: 0;
  color: var(--global-theme-color);
}

.course-description {
  color: var(--global-text-color-light);
  font-size: 1.1rem;
  margin-bottom: 1.5rem;
  line-height: 1.6;
}

.course-section {
  margin-top: 1.5rem;
  background-color: var(--global-code-bg-color);
  border-radius: 6px;
  padding: 1.5rem;
  margin-bottom: 1.5rem;
}

.section-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
}

.section-header h3 {
  margin: 0;
  font-size: 1.3rem;
  color: var(--global-theme-color);
}

.github-link {
  text-decoration: none;
  color: var(--global-theme-color);
  transition: color 0.2s;
  white-space: nowrap;
}

.github-link:hover {
  color: var(--global-hover-color, #0056b3);
}

.table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 1rem;
}

.table td, .table th {
  padding: 0.85rem 1rem;
  border-bottom: 1px solid var(--global-divider-color);
  font-size: 1rem;
  text-align: left;
}

.table thead th {
  text-align: left;
  border-bottom: 2px solid var(--global-divider-color);
}

.table tbody tr:last-child td {
  border-bottom: none;
}

.table tbody tr:hover {
  background-color: rgba(0, 0, 0, 0.02);
}

.badge-link {
  display: inline-block;
  margin: 2px;
  transition: transform 0.2s;
}

.badge-link:hover {
  transform: translateY(-2px);
}
</style>